{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'D:\\Evans microbial community\\data_for_pipeline\\metadata_full_MMPRNT_G5.LC_LUX_trunc_rar_016017_v2.txt'\n",
    "#label = 'D:\\Evans microbial community\\data_for_pipeline\\ELSA_module_016017_LUX_OTU_sum_MMPRNT_G5_LC_LUX_016017.txt'\n",
    "label = 'D:\\Evans microbial community\\data_for_pipeline\\Rarefied_diversity_MMPRNT_G5_LC_LUX_016017.txt'\n",
    "site = 'LUX'\n",
    "site_not_used = 'LC'\n",
    "cv_num = 10\n",
    "test_size = 0.1 ### what the proportion of your data you want to hold out as test set, \n",
    "                ### which will never be seen when you train the model\n",
    "feature_2_onehotencoding = ['FertStatus','thermal_two_year','thermal_2019','thermal_2018']\n",
    "save_model_name = 'Multioutput_model_network_modules.sav'\n",
    "save_result_name = 'Result_Multioutput_network_modules.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file, sep='\\t', index_col = 0, header = 0)\n",
    "if 'ELSA' in label:\n",
    "    df_lable = pd.read_csv(label, sep='\\t', index_col = 42, header = 0)\n",
    "if 'Rarefied' in label:\n",
    "    df_lable = pd.read_csv(label, sep='\\t', index_col = 0, header = 0)\n",
    "ML_matrix = pd.concat([df_lable,df], axis=1, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target_site = ML_matrix.loc[ML_matrix['siteID']==site]\n",
    "df_target_site = df_target_site.drop([\"collectionDate\",\"siteID\",\\\n",
    "                                             \"UTM_Lat_Cord\",\"UTM_Lon_Cord\"],axis=1)\n",
    "\n",
    "df_other_site = ML_matrix.loc[ML_matrix['siteID']==site_not_used]\n",
    "df_other_site = df_other_site.drop([\"collectionDate\",\"siteID\",\\\n",
    "                                             \"UTM_Lat_Cord\",\"UTM_Lon_Cord\"],axis=1)\n",
    "\n",
    "df_target_site[\"thermal_two_year\"].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data to traning and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(df_target_site, \\\n",
    "                                       test_size=test_size, random_state=42)\n",
    "X_train = train_set.drop(df_lable.columns, axis=1) \n",
    "X_test = test_set.drop(df_lable.columns, axis=1)\n",
    "X_on_test_site = df_other_site.drop(df_lable.columns, axis=1)\n",
    "\n",
    "y_train = train_set[df_lable.columns]\n",
    "y_test = test_set[df_lable.columns]\n",
    "y_on_test_site = df_other_site[df_lable.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OneHotEncoding, handle with NaN data (keep them as NaN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit on training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def OneHotEncoder_fit_transform(df,feature_2_onehotencoding):\n",
    "    new_columns = []\n",
    "    Onehot = {}\n",
    "    col_2_1hot = df.loc[:,feature_2_onehotencoding]\n",
    "    for col in feature_2_onehotencoding:\n",
    "        Onehot[col] = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "        c_1hot_use = pd.DataFrame(col_2_1hot.loc[col_2_1hot.loc[:,col].notna(),col])\n",
    "        c_1hot_na = pd.DataFrame(col_2_1hot.loc[col_2_1hot.loc[:,col].isna(),col])\n",
    "        if c_1hot_na.shape[0] == 0:\n",
    "            c_1hot_encoded = pd.DataFrame(Onehot[col].fit_transform(c_1hot_use))\n",
    "            c_1hot_encoded.columns = [col + '_' + '%s'%sub for sub in Onehot[col].categories_[0]]\n",
    "            c_1hot_encoded.index = col_2_1hot.index\n",
    "            for columns in c_1hot_encoded.columns:\n",
    "                new_columns.append(columns)\n",
    "        if c_1hot_na.shape[0] != 0:\n",
    "            c_1hot_encoded = pd.DataFrame(Onehot[col].fit_transform(c_1hot_use))\n",
    "            c_1hot_encoded.columns = [col + '_' + '%s'%sub for sub in Onehot[col].categories_[0]]\n",
    "            c_1hot_encoded.index = c_1hot_use.index\n",
    "            for columns in c_1hot_encoded.columns:\n",
    "                c_1hot_na[columns] = np.nan\n",
    "                new_columns.append(columns)\n",
    "            c_1hot_na = c_1hot_na.drop(col,axis=1)\n",
    "            c_1hot_encoded = pd.concat([c_1hot_encoded,c_1hot_na],axis=0)\n",
    "        df = pd.concat([df,c_1hot_encoded],axis=1)\n",
    "    return(df,Onehot,new_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### transform on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OneHotEncoder_transform(df,feature_2_onehotencoding,Onehot):\n",
    "    col_2_1hot = df.loc[:,feature_2_onehotencoding]\n",
    "    for col in feature_2_onehotencoding:\n",
    "        c_1hot_use = pd.DataFrame(col_2_1hot.loc[col_2_1hot.loc[:,col].notna(),col])\n",
    "        c_1hot_na = pd.DataFrame(col_2_1hot.loc[col_2_1hot.loc[:,col].isna(),col])\n",
    "        if c_1hot_na.shape[0] == 0:\n",
    "            c_1hot_encoded = pd.DataFrame(Onehot[col].transform(c_1hot_use))\n",
    "            c_1hot_encoded.columns = [col + '_' + '%s'%sub for sub in Onehot[col].categories_[0]]\n",
    "            c_1hot_encoded.index = col_2_1hot.index\n",
    "            df = pd.concat([df,c_1hot_encoded],axis=1)\n",
    "        if c_1hot_na.shape[0] != 0 and c_1hot_use.shape[0] != 0:\n",
    "            c_1hot_encoded = pd.DataFrame(Onehot[col].transform(c_1hot_use))\n",
    "            c_1hot_encoded.columns = [col + '_' + '%s'%sub for sub in Onehot[col].categories_[0]]\n",
    "            c_1hot_encoded.index = c_1hot_use.index\n",
    "            for columns in c_1hot_encoded.columns:\n",
    "                c_1hot_na[columns] = np.nan\n",
    "            c_1hot_na = c_1hot_na.drop(col,axis=1)\n",
    "            c_1hot_encoded = pd.concat([c_1hot_encoded,c_1hot_na],axis=0)\n",
    "            df = pd.concat([df,c_1hot_encoded],axis=1)\n",
    "        if c_1hot_use.shape[0] == 0:\n",
    "            columns = [col + '_' + '%s'%sub for sub in Onehot[col].categories_[0]]\n",
    "            for column in columns:\n",
    "                c_1hot_na[column] = np.nan\n",
    "            c_1hot_na = c_1hot_na.drop(col,axis=1)  \n",
    "            df = pd.concat([df,c_1hot_na],axis=1)\n",
    "    return(df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\softinstall\\Anaconda3\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py:25: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "D:\\softinstall\\Anaconda3\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py:25: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "D:\\softinstall\\Anaconda3\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py:25: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "D:\\softinstall\\Anaconda3\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py:19: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "D:\\softinstall\\Anaconda3\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py:19: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "D:\\softinstall\\Anaconda3\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py:19: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, Onehot, new_columns = OneHotEncoder_fit_transform(X_train,feature_2_onehotencoding)\n",
    "X_test = OneHotEncoder_transform(X_test,feature_2_onehotencoding,Onehot)\n",
    "X_on_test_site = OneHotEncoder_transform(X_on_test_site,feature_2_onehotencoding,Onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop the original columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(feature_2_onehotencoding,axis=1)\n",
    "X_test = X_test.drop(feature_2_onehotencoding,axis=1)\n",
    "X_on_test_site = X_on_test_site.drop(feature_2_onehotencoding,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute missing data using KNN, five Ks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. drop features with >50% missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Miss_count = X_train.count(0)\n",
    "Col_to_drop = Miss_count[Miss_count <= 0.5*X_train.shape[0]].index.tolist()\n",
    "Col_to_drop\n",
    "X_train.drop(Col_to_drop,axis=1,inplace=True)\n",
    "X_test.drop(Col_to_drop,axis=1,inplace=True)\n",
    "X_on_test_site.drop(Col_to_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import KNNImputer\n",
    "class KNNImputer_Ks(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, *Ks):\n",
    "        self.Ks = Ks\n",
    "    def fit(self, X,Ks):\n",
    "        D_imputer = {}        \n",
    "        for k in [3,4,5,6,7]:\n",
    "            imputer = KNNImputer(n_neighbors=k)\n",
    "            D_imputer[k] = imputer.fit(X)              \n",
    "        return D_imputer\n",
    "    def transform(self, X):\n",
    "        Impute_train = {}\n",
    "        for k in [3,4,5,6,7]:\n",
    "            Impute_train[k] = pd.DataFrame(D_imputer[k].transform(X))\n",
    "            Impute_train[k].index = X.index\n",
    "            Impute_train[k].columns = X.columns \n",
    "            if k == 3:\n",
    "                Imputed = Impute_train[k].copy(deep=True)\n",
    "                Imputed.loc[:,:] = 0\n",
    "            Imputed = Imputed.add(Impute_train[k],fill_value=0)\n",
    "        return Imputed/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_knn = KNNImputer_Ks()\n",
    "D_imputer = imputer_knn.fit(X_train, Ks=\"3,4,5,6,7\")\n",
    "X_train_KNN = imputer_knn.transform(X_train)\n",
    "X_test_KNN = imputer_knn.transform(X_test)\n",
    "X_on_test_site_KNN =  imputer_knn.transform(X_on_test_site)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### round the imputed values for binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in new_columns:\n",
    "    X_train_KNN[col] = round(X_train_KNN[col],0)\n",
    "    X_test_KNN[col] = round(X_test_KNN[col],0)\n",
    "    X_on_test_site_KNN[col] = round(X_on_test_site_KNN[col],0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "if y_train.shape[1] == 1:\n",
    "    param_grid = {'max_depth':[3, 5, 10], \\\n",
    "              'max_features': [0.1, 0.5, 'sqrt', 'log2', None], \\\n",
    "              'n_estimators': [10, 100,500,1000]}\n",
    "    Reg_Mol = RandomForestRegressor()\n",
    "    grid_search = GridSearchCV(Reg_Mol, param_grid, cv=cv_num, \\\n",
    "                           scoring='neg_mean_squared_error', verbose=2,n_jobs=5)\n",
    "    grid_search.fit(X_train_KNN, y_train)\n",
    "if y_train.shape[1] > 1:    \n",
    "    gsc = GridSearchCV(\n",
    "                estimator=RandomForestRegressor(),\n",
    "                #param_grid={'max_depth':[3, 5, 10], \\\n",
    "                #  'max_features': [0.1, 0.5, 'sqrt', 'log2', None], \\\n",
    "                #  'n_estimators': [10, 100,500,1000]},\n",
    "                param_grid={'max_depth':[3, 5, 10], \\\n",
    "                  'max_features': [0.1], \\\n",
    "                  'n_estimators': [10]},        \n",
    "                cv=cv_num, scoring='neg_mean_squared_error', verbose=2, n_jobs=5)\n",
    "    grid_search = MultiOutputRegressor(gsc).fit(X_train_KNN, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.estimators_[2].best_estimator_\n",
    "grid_search.estimators_[2].best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCC_multioutput(a,b):\n",
    "    R = []\n",
    "    for i in range(0,a.shape[1]):\n",
    "        R.append(np.corrcoef(np.array(a.loc[:,i]), np.array(b.loc[:,i]))[0,1])\n",
    "                 \n",
    "    return (np.array(R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "cv_pred = pd.DataFrame(cross_val_predict(estimator=grid_search, X=X_train_KNN, y=y_train, cv=cv_num))\n",
    "cv_pred.columns = y_train.columns\n",
    "cv_pred.index = y_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_mse = mean_squared_error(y_train, cv_pred,multioutput='raw_values')\n",
    "cv_evs = explained_variance_score(y_train, cv_pred,multioutput='raw_values')\n",
    "cv_r2 = r2_score(y_train, cv_pred,multioutput='raw_values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = y_train\n",
    "b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot do label indexing on <class 'pandas.core.indexes.base.Index'> with these indexers [0] of <class 'int'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-995f77a7a4d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcv_cor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCC_multioutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-46-29b6a0838ee1>\u001b[0m in \u001b[0;36mPCC_multioutput\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorrcoef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\softinstall\\Anaconda3\\envs\\tf2\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1416\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1419\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\softinstall\\Anaconda3\\envs\\tf2\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    803\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    806\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\softinstall\\Anaconda3\\envs\\tf2\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    927\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_label_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 929\u001b[1;33m                 \u001b[0msection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m                 \u001b[1;31m# we have yielded a scalar ?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\softinstall\\Anaconda3\\envs\\tf2\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1848\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1849\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1850\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1851\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\softinstall\\Anaconda3\\envs\\tf2\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1724\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1725\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1726\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1727\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\softinstall\\Anaconda3\\envs\\tf2\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_scalar_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[1;31m# a scalar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_convert_slice_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\softinstall\\Anaconda3\\envs\\tf2\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_convert_scalar_indexer\u001b[1;34m(self, key, kind)\u001b[0m\n\u001b[0;32m   3136\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mkind\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"loc\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3137\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3138\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invalid_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"label\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\softinstall\\Anaconda3\\envs\\tf2\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_invalid_indexer\u001b[1;34m(self, form, key)\u001b[0m\n\u001b[0;32m   3338\u001b[0m             \u001b[1;34m\"cannot do {form} indexing on {klass} with these \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3339\u001b[0m             \"indexers [{key}] of {kind}\".format(\n\u001b[1;32m-> 3340\u001b[1;33m                 \u001b[0mform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3341\u001b[0m             )\n\u001b[0;32m   3342\u001b[0m         )\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot do label indexing on <class 'pandas.core.indexes.base.Index'> with these indexers [0] of <class 'int'>"
     ]
    }
   ],
   "source": [
    "cv_cor = PCC_multioutput(y_train, cv_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_Richness</th>\n",
       "      <th>full_InvSimpson</th>\n",
       "      <th>full_Evenness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AH11</th>\n",
       "      <td>2326</td>\n",
       "      <td>297.720060</td>\n",
       "      <td>0.127997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMPRNT235</th>\n",
       "      <td>2417</td>\n",
       "      <td>276.131726</td>\n",
       "      <td>0.114246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMPRNT6</th>\n",
       "      <td>2095</td>\n",
       "      <td>196.192300</td>\n",
       "      <td>0.093648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMPRNT157</th>\n",
       "      <td>2549</td>\n",
       "      <td>267.525602</td>\n",
       "      <td>0.104953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMPRNT243</th>\n",
       "      <td>2178</td>\n",
       "      <td>47.615692</td>\n",
       "      <td>0.021862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMPRNT245</th>\n",
       "      <td>2316</td>\n",
       "      <td>226.449275</td>\n",
       "      <td>0.097776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMPRNT302</th>\n",
       "      <td>1872</td>\n",
       "      <td>162.028336</td>\n",
       "      <td>0.086554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AF18</th>\n",
       "      <td>2066</td>\n",
       "      <td>142.413626</td>\n",
       "      <td>0.068932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F18</th>\n",
       "      <td>2464</td>\n",
       "      <td>246.901388</td>\n",
       "      <td>0.100203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMPRNT299</th>\n",
       "      <td>2139</td>\n",
       "      <td>280.082232</td>\n",
       "      <td>0.130941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>599 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           full_Richness  full_InvSimpson  full_Evenness\n",
       "AH11                2326       297.720060       0.127997\n",
       "MMPRNT235           2417       276.131726       0.114246\n",
       "MMPRNT6             2095       196.192300       0.093648\n",
       "MMPRNT157           2549       267.525602       0.104953\n",
       "MMPRNT243           2178        47.615692       0.021862\n",
       "...                  ...              ...            ...\n",
       "MMPRNT245           2316       226.449275       0.097776\n",
       "MMPRNT302           1872       162.028336       0.086554\n",
       "AF18                2066       142.413626       0.068932\n",
       "F18                 2464       246.901388       0.100203\n",
       "MMPRNT299           2139       280.082232       0.130941\n",
       "\n",
       "[599 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "if y_train.shape[1] == 1:\n",
    "    param_grid = {'max_depth':[3, 5, 10], \\\n",
    "              'max_features': [0.1, 0.5, 'sqrt', 'log2', None], \\\n",
    "              'n_estimators': [10, 100,500,1000]}\n",
    "    Reg_Mol = RandomForestRegressor()\n",
    "    \n",
    "if y_train.shape[1] > 1:\n",
    "    param_grid = {'estimator__max_depth':[3], \\\n",
    "              'estimator__max_features': [None], \\\n",
    "              'estimator__n_estimators': [10, 100,500,1000]}    \n",
    "    Reg_Mol = MultiOutputRegressor(RandomForestRegressor(), n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "if y_train.shape[1] == 1:\n",
    "    param_grid = {'max_depth':[3, 5, 10], \\\n",
    "              'max_features': [0.1, 0.5, 'sqrt', 'log2', None], \\\n",
    "              'n_estimators': [10, 100,500,1000]}\n",
    "    Reg_Mol = RandomForestRegressor()\n",
    "    \n",
    "if y_train.shape[1] > 1:\n",
    "    param_grid = {'estimator__max_depth':[3, 5, 10], \\\n",
    "              'estimator__max_features': [0.1, 0.5, 'sqrt', 'log2', None], \\\n",
    "              'estimator__n_estimators': [10, 100,500,1000]}    \n",
    "    Reg_Mol = MultiOutputRegressor(RandomForestRegressor(), n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'max_features': None, 'n_estimators': 500}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.estimators_[2].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(Reg_Mol, param_grid, cv=cv_num, \\\n",
    "                           scoring='neg_mean_squared_error', verbose=2,n_jobs=5)\n",
    "grid_search.fit(X_train_KNN, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = grid_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. cross-validation and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "parameter2use = grid_search.best_params_\n",
    "\n",
    "if y_train.shape[1] == 1:\n",
    "    Reg = RandomForestRegressor(n_estimators=parameter2use['n_estimators'],\\\n",
    "                            max_depth=parameter2use['max_depth'],\\\n",
    "                            max_features= parameter2use['max_features'],\\\n",
    "                            criterion='mse', random_state=42)    \n",
    "if y_train.shape[1] > 1:\n",
    "    Reg = MultiOutputRegressor(RandomForestRegressor(n_estimators=parameter2use['estimator__n_estimators'],\\\n",
    "                            max_depth=parameter2use['estimator__max_depth'],\\\n",
    "                            max_features= parameter2use['estimator__max_features'],\\\n",
    "                            criterion='mse', random_state=42), n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse: Mean squared error regression loss\n",
    "# evs: Explained variance regression score\n",
    "# r2: (coefficient of determination) regression score. \n",
    "    # Best possible score is 1.0 and it can be negative \n",
    "    # (because the model can be arbitrarily worse). \n",
    "    # A constant model that always predicts the expected value of y, \n",
    "    # disregarding the input features, would get a R^2 score of 0.0.\n",
    "# cor: Pearson Correlation Coefficient between true y and predicted y\n",
    "if y_train.shape[1] == 1:\n",
    "    cv_pred = cross_val_predict(estimator=Reg, X=X_train_KNN, y=y_train, cv=cv_num)\n",
    "    cv_mse = mean_squared_error(y_train, cv_pred)\n",
    "    cv_evs = explained_variance_score(y_train, cv_pred)\n",
    "    cv_r2 = r2_score(y_train, cv_pred)\n",
    "    cv_cor = np.corrcoef(np.array(y_train), cv_pred)[0,1]\n",
    "if y_train.shape[1] > 1:\n",
    "    cv_pred = pd.DataFrame(cross_val_predict(estimator=Reg, X=X_train_KNN, y=y_train, cv=cv_num))\n",
    "    cv_pred.columns = y_train.columns\n",
    "    cv_pred.index = y_train.index\n",
    "    cv_mse = mean_squared_error(y_train, cv_pred,multioutput='raw_values')\n",
    "    cv_evs = explained_variance_score(y_train, cv_pred,multioutput='raw_values')\n",
    "    cv_r2 = r2_score(y_train, cv_pred,multioutput='raw_values')\n",
    "    cv_cor = np.corrcoef(np.array(y_train), cv_pred)[0,1]\n",
    "    \n",
    "# need to figure out how to get the multioutput PCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01499697, -0.02130138, -0.02601508, -0.02418396, -0.01632604,\n",
       "       -0.00672137, -0.01345846, -0.01587304, -0.02855328,  0.00227371,\n",
       "       -0.01996841, -0.02209687, -0.00190153, -0.02549373, -0.01205259,\n",
       "       -0.02363729, -0.02879485, -0.0216127 , -0.01878749, -0.01627443,\n",
       "       -0.01860381, -0.01431295, -0.01635258, -0.00749156, -0.01046488,\n",
       "       -0.018761  , -0.02371008, -0.01564974, -0.00690794, -0.01592981,\n",
       "        0.00831275, -0.0267923 , -0.01313112, -0.02191073, -0.0210646 ,\n",
       "       -0.01413702,  0.0021471 , -0.0128265 , -0.00231004, -0.03602125,\n",
       "       -0.02395407, -0.01610284])"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_evs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reg.fit(X_train_KNN,y_train)\n",
    "pred_train = Reg.predict(X_train_KNN)\n",
    "if y_train.shape[1] == 1:\n",
    "    train_mse = mean_squared_error(y_train, pred_train)\n",
    "    train_evs = explained_variance_score(y_train, pred_train)\n",
    "    train_r2 = r2_score(y_train, pred_train)\n",
    "    train_cor = np.corrcoef(np.array(y_train), pred_train)[0,1]\n",
    "if y_train.shape[1] > 1:\n",
    "    pred_train = pd.DataFrame(pred_train)\n",
    "    pred_train.columns = y_train.columns\n",
    "    pred_train.index = y_train.index\n",
    "    train_mse = mean_squared_error(y_train, pred_train,multioutput='raw_values')\n",
    "    train_evs = explained_variance_score(y_train, pred_train,multioutput='raw_values')\n",
    "    train_r2 = r2_score(y_train, pred_train,multioutput='raw_values')\n",
    "    train_cor = np.corrcoef(np.array(y_train), pred_train)[0,1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = Reg.predict(X_test_KNN)\n",
    "if y_train.shape[1] == 1:\n",
    "    test_mse = mean_squared_error(y_test, pred_test)\n",
    "    test_evs = explained_variance_score(y_test, pred_test)\n",
    "    test_r2 = r2_score(y_test, pred_test)\n",
    "    test_cor = np.corrcoef(np.array(y_test), pred_test)\n",
    "if y_train.shape[1] > 1:\n",
    "    pred_test = pd.DataFrame(pred_test)\n",
    "    pred_test.columns = y_test.columns\n",
    "    pred_test.index = y_test.index\n",
    "    test_mse = mean_squared_error(y_test, pred_test,multioutput='raw_values')\n",
    "    test_evs = explained_variance_score(y_test, pred_test,multioutput='raw_values')\n",
    "    test_r2 = r2_score(y_test, pred_test,multioutput='raw_values')\n",
    "    test_cor = np.corrcoef(np.array(y_test), pred_test)[0,1]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_on_test_site = Reg.predict(X_on_test_site_KNN)\n",
    "if y_train.shape[1] == 1:\n",
    "    test_site_mse = mean_squared_error(y_on_test_site, pred_on_test_site)\n",
    "    test_site_evs = explained_variance_score(y_on_test_site, pred_on_test_site)\n",
    "    test_site_r2 = r2_score(y_on_test_site, pred_on_test_site)\n",
    "    test_site_cor = np.corrcoef(np.array(y_on_test_site), pred_on_test_site)[0,1]\n",
    "if y_train.shape[1] > 1:\n",
    "    pred_on_test_site = pd.DataFrame(pred_on_test_site)\n",
    "    pred_on_test_site.columns = y_on_test_site.columns\n",
    "    pred_on_test_site.index = y_on_test_site.index\n",
    "    test_site_mse = mean_squared_error(y_on_test_site, pred_on_test_site,multioutput='raw_values')\n",
    "    test_site_evs = explained_variance_score(y_on_test_site, pred_on_test_site,multioutput='raw_values')\n",
    "    test_site_r2 = r2_score(y_on_test_site, pred_on_test_site,multioutput='raw_values')\n",
    "    test_site_cor = np.corrcoef(np.array(y_on_test_site), pred_on_test_site)[0,1]            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(Reg, open(save_model_name, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = open(save_result_name,'w')\n",
    "out.write('The model is built using data from %s, and applied to %s and %s.\\n\\n'%(site,site,site_not_used))\n",
    "out.write('There are %s training instances.\\n'%X_train_KNN.shape[0])\n",
    "out.write('There are %s test instances.\\n'%X_test_KNN.shape[0])\n",
    "out.write('There are %s instances in the other site.\\n\\n'%X_on_test_site_KNN.shape[0])\n",
    "out.write('The model is built using RandomForestRegressor, with:\\n')\n",
    "if y_train.shape[1] == 1:\n",
    "    out.write('\\tn_estimators: %s\\n'%parameter2use['n_estimators'])\n",
    "    out.write('\\tmax_depth: %s\\n'%parameter2use['max_depth'])\n",
    "    out.write('\\tmax_features: %s\\n\\n'%parameter2use['max_features'])\n",
    "if y_train.shape[1] > 1:\n",
    "    out.write('\\tn_estimators: %s\\n'%parameter2use['estimator__n_estimators'])\n",
    "    out.write('\\tmax_depth: %s\\n'%parameter2use['estimator__max_depth'])\n",
    "    out.write('\\tmax_features: %s\\n\\n'%parameter2use['estimator__max_features'])    \n",
    "out.write('There are %s feature used\\n\\n'%X_train_KNN.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.write('Prediction\\tmse\\tevs\\tr2\\tPCC\\n')\n",
    "out.write('CV\\t%s\\t%s\\t%s\\t%s\\n'%(cv_mse,cv_evs,cv_r2,cv_cor))\n",
    "out.write('Train\\t%s\\t%s\\t%s\\t%s\\n'%(train_mse,train_evs,train_r2,train_cor))\n",
    "out.write('Test\\t%s\\t%s\\t%s\\t%s\\n'%(test_mse,test_evs,test_r2,test_cor))\n",
    "out.write('Other_site\\t%s\\t%s\\t%s\\t%s\\n\\n'%(test_site_mse,test_site_evs,test_site_r2,test_site_cor))\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = pd.DataFrame({'Feature':X_train_KNN.columns, 'Importance':Reg.feature_importances_})\n",
    "imp_sorted = imp.sort_values(by='Importance', ascending=False)\n",
    "imp_sorted.to_csv(save_result_name.split('.txt')[0] + '_imp.txt', index=False, header=True,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the importance direction in the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
