{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the gene-pathway annotation\n",
    "df = pd.read_csv('Sly_pathway_annotation_20180827_with_expression_5_members.txt',header=None,index_col=None,sep='\\t')\n",
    "# gene-pathway annotation for only non-overlapping genes in 85 pathways\n",
    "df_uni = pd.read_csv('Sly_pathway_annotation_20190117_with_expression_5_members_nonoverlapping.txt',header=None,index_col=None,sep='\\t')\n",
    "df.columns = ['Pathway','Gene']\n",
    "pathway = df_uni[0].unique()\n",
    "# to get back genes with multiple pathway annotation in only those 85 pathways\n",
    "df_85 = df[df['Pathway'].isin(pathway)]\n",
    "gene = df_85['Gene'].unique()\n",
    "df_85.index = df_85['Gene']\n",
    "df_85 = df_85.drop(['Gene'],axis=1)\n",
    "df_85.columns = ['Pathway']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make the multiple labels, using OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encoder = OneHotEncoder() # or cat_encoder = OneHotEncoder(sparse=False)\n",
    "df_85_1hot = cat_encoder.fit_transform(df_85)\n",
    "labels = pd.DataFrame(df_85_1hot.toarray()) # or labels = pd.DataFrame(df_85_1hot)\n",
    "labels.columns = cat_encoder.categories_[0]\n",
    "labels.index = df_85.index\n",
    "# group rows with same index ID, add up the 1s\n",
    "gp = labels.groupby(level=0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parse the expression matrix, here FCs in all combination were used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = pd.read_csv('Results_Fold_changes_all_combination_Sly_20180124.txt',header=0,index_col=None,sep='\\t')\n",
    "exp_85 = exp[exp['gene'].isin(gene)]\n",
    "exp_85.index = exp_85['gene']\n",
    "exp_85 = exp_85.drop('gene',axis=1)\n",
    "res = pd.concat([gp,exp_85],axis=1)\n",
    "# save the multilable matrix\n",
    "res.to_csv('Multilabel_85_pathways_matrix_all_FC.txt',index=True, header=True,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Multilabel_85_pathways_matrix_all_FPKM.txt',header=0,index_col=0,sep='\\t')\n",
    "X = df.iloc[:,85:]\n",
    "y = df.iloc[:,0:85]\n",
    "# count no of pathways each gene was annotated\n",
    "freq = y.astype(bool).sum(axis=1)\n",
    "# get genes with multiple pathway annotation\n",
    "freq2 = freq[freq>1]\n",
    "# get the corresponding labels\n",
    "y2 = y.loc[y.index.isin(freq2.index),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count no of genes annotated in each pathway\n",
    "freq3 = y2.astype(bool).sum(axis=0)\n",
    "sorted(freq3,reverse=True)\n",
    "# get pathways with more than 10 genes\n",
    "freq3[freq3 > 10]\n",
    "y3 = y.loc[:,['PWY-321','PWY-361','PWY-5690','PWY-6443','PWY-6733']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PWY-321</th>\n",
       "      <th>PWY-361</th>\n",
       "      <th>PWY-5690</th>\n",
       "      <th>PWY-6443</th>\n",
       "      <th>PWY-6733</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NP_001234001.1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NP_001234005.1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NP_001234277.1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NP_001234574.1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NP_001234767.1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                PWY-321  PWY-361  PWY-5690  PWY-6443  PWY-6733\n",
       "NP_001234001.1      0.0      0.0       1.0       0.0       0.0\n",
       "NP_001234005.1      0.0      0.0       1.0       0.0       0.0\n",
       "NP_001234277.1      0.0      0.0       1.0       0.0       0.0\n",
       "NP_001234574.1      0.0      0.0       1.0       0.0       0.0\n",
       "NP_001234767.1      0.0      0.0       0.0       1.0       0.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for the remaining dataset, get rid of genes which are not annotated in the 5 pathways\n",
    "freq4 = y3.astype(bool).sum(axis=1)\n",
    "freq5 = freq4[freq4 > 0]\n",
    "y4 = y3.loc[y3.index.isin(freq5.index),:]\n",
    "y4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.loc[X.index.isin(y4.index),:]\n",
    "y = y4\n",
    "df = pd.concat([y,X],axis=1)\n",
    "df.to_csv('Multilabel_5_pathways_matrix_all_FPKM.txt',index=True, header=True,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data to training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Multilabel_5_pathways_matrix_all_FPKM.txt',header=0,index_col=0,sep='\\t')\n",
    "X = df.iloc[:,5:]\n",
    "y = df.iloc[:,0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StratifiedKFold can't be used in multi-label cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import StratifiedKFold\n",
    "#skfolds = StratifiedKFold(n_splits=5, random_state=42,shuffle=True)\n",
    "#train_index, test_index = skfolds.split(X, y)\n",
    "# ValueError: Supported target types are: ('binary', 'multiclass'). Got 'multilabel-indicator' instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### !!Note that IterativeStratification can't freeze the random state, therefore every run would lead to different split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skmultilearn\n",
    "from skmultilearn.model_selection import IterativeStratification\n",
    "import numpy as np\n",
    "#k_fold = IterativeStratification(n_splits=5, order=1)\n",
    "#Split = pd.DataFrame(k_fold.split(X, y))\n",
    "#X_train = X.iloc[Split.iloc[0,0],:]\n",
    "#y_train = y.iloc[Split.iloc[0,0],:]\n",
    "#X_test = X.iloc[Split.iloc[0,1],:]\n",
    "#y_test = y.iloc[Split.iloc[0,1],:]\n",
    "#ID_train = y_train.index.tolist()\n",
    "#pd.DataFrame(ID_train).to_csv('Multilable_training_ID.txt',index=False, header=False,sep=\"\\t\")\n",
    "#ID_test = y_test.index.tolist()\n",
    "#pd.DataFrame(ID_test).to_csv('Multilable_test_ID.txt',index=False, header=False,sep=\"\\t\")\n",
    "# count non zeros for each column (pathway annotation)\n",
    "#y_train.astype(bool).sum(axis=0)\n",
    "#y_test.astype(bool).sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reload the saved training and test gene IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 5)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Multilabel_5_pathways_matrix_all_FPKM.txt',header=0,index_col=0,sep='\\t')\n",
    "train_id = pd.read_csv('Multilable_training_ID.txt',header=None,index_col=None,sep='\\t')\n",
    "test_id = pd.read_csv('Multilable_test_ID.txt',header=None,index_col=None,sep='\\t')\n",
    "X_train = df.loc[df.index.isin(train_id[0]),:].iloc[:,5:]\n",
    "y_train = df.iloc[df.index.isin(train_id[0]),:].iloc[:,0:5]\n",
    "X_test = df.loc[df.index.isin(test_id[0]),:].iloc[:,5:]\n",
    "y_test = df.iloc[df.index.isin(test_id[0]),:].iloc[:,0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import KNNImputer\n",
    "class KNNImputer_Ks(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, *Ks):\n",
    "        self.Ks = Ks\n",
    "    def fit(self, X,Ks):\n",
    "        D_imputer = {}        \n",
    "        for k in [3,4,5,6,7]:\n",
    "            imputer = KNNImputer(n_neighbors=k)\n",
    "            D_imputer[k] = imputer.fit(X)              \n",
    "        return D_imputer\n",
    "    def transform(self, X):\n",
    "        Impute_train = {}\n",
    "        for k in [3,4,5,6,7]:\n",
    "            Impute_train[k] = pd.DataFrame(D_imputer[k].transform(X))\n",
    "            Impute_train[k].index = X.index\n",
    "            Impute_train[k].columns = X.columns \n",
    "            if k == 3:\n",
    "                Imputed = Impute_train[k].copy(deep=True)\n",
    "                Imputed.loc[:,:] = 0\n",
    "            Imputed = Imputed.add(Impute_train[k],fill_value=0)\n",
    "        return Imputed/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_knn = KNNImputer_Ks()\n",
    "D_imputer = imputer_knn.fit(X_train, Ks=\"3,4,5,6,7\")\n",
    "X_train_KNN = imputer_knn.transform(X_train)\n",
    "X_test_KNN = imputer_knn.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_KNN = scaler.fit_transform(X_train_KNN)\n",
    "X_test_KNN = scaler.transform(X_test_KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "knn_clf = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors':[3,4,5,10,15,20,25], \\\n",
    "              'weights': ['uniform', 'distance'], \\\n",
    "              'metric': ['euclidean','manhattan','minkowski']}\n",
    "# add randomize search\n",
    "# cut down the feature size to 30\n",
    "# top 5 pathways\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=5)]: Done 210 out of 210 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='deprecated', n_jobs=5,\n",
       "             param_grid={'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
       "                         'n_neighbors': [3, 4, 5, 10, 15, 20, 25],\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_weighted', verbose=2)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(knn_clf, param_grid, cv=5, scoring='f1_weighted', verbose=2, n_jobs=5)\n",
    "gs.fit(X_train_KNN,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46151055, 0.20147293, 0.35882353, 0.40320513, 0.27708333])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "parameter2use = gs.best_params_\n",
    "KNC_clf = KNeighborsClassifier(metric=parameter2use['metric'],\\\n",
    "                            n_neighbors=parameter2use['n_neighbors'],\\\n",
    "                            weights= parameter2use['weights'])\n",
    "cv_pred = cross_val_predict(estimator=KNC_clf, X=X_train_KNN, y=y_train, cv=5)\n",
    "cv_score = cross_val_score(estimator=KNC_clf, X=X_train_KNN, y=y_train, \\\n",
    "                           cv=5,scoring='f1_weighted')\n",
    "# using three F1 values: macro, average, weighted\n",
    "cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    23\n",
       "1    21\n",
       "2    22\n",
       "3    33\n",
       "4    26\n",
       "dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv_pred).astype(bool).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24489796, 0.30769231, 0.3902439 , 0.39506173, 0.36363636])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "F1_weighted_cv = f1_score(y_train,cv_pred,average = 'weighted')\n",
    "f1_score(y_train,cv_pred,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4915069057926201"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNC_clf.fit(X_train_KNN,y_train)\n",
    "test_pred = KNC_clf.predict(X_test_KNN)\n",
    "F1_weighted_test = f1_score(y_test,test_pred,average = 'weighted')\n",
    "F1_weighted_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48718614718614717"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1_macro_test = f1_score(y_test,test_pred,average = 'macro')\n",
    "F1_macro_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42857143, 0.42857143, 0.5       , 0.54545455, 0.53333333])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1_test = f1_score(y_test,test_pred,average = None)\n",
    "F1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4444444444444444"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate metrics for each instance, and find their average (only meaningful for multilabel classification where this differs from accuracy_score).\n",
    "F1_sample_test = f1_score(y_test,test_pred,average = 'samples')\n",
    "F1_sample_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f1 score for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test,test_pred,average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "RF_clf = RandomForestClassifier()\n",
    "param_grid = {'max_depth':[3, 5, 10], \\\n",
    "              'max_features': [0.1, 0.5, 'sqrt', 'log2', None], \\\n",
    "              'n_estimators': [10,100,500,1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=5)]: Done 152 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=5)]: Done 300 out of 300 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=5,\n",
       "             param_grid={'max_depth': [3, 5, 10],\n",
       "                         'max_features': [0.1, 0.5, 'sqrt', 'log2', None],\n",
       "                         'n_estimators': [10, 100, 500, 1000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_weighted', verbose=2)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(RF_clf, param_grid, cv=5, scoring='f1_weighted', verbose=2,\\\n",
    "                 n_jobs=5)\n",
    "gs.fit(X_train_KNN,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'max_features': 0.5, 'n_estimators': 10}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'max_depth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-147-db433a47ff2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mparameter2use\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#parameter2use = {'max_depth':3,'max_features': 0.1,'n_estimators':100}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m RF_clf = RandomForestClassifier(max_depth=parameter2use['max_depth'],\\\n\u001b[0m\u001b[0;32m      6\u001b[0m                             \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparameter2use\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'max_features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                             \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mparameter2use\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'n_estimators'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'max_depth'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "parameter2use = gs.best_params_\n",
    "#parameter2use = {'max_depth':3,'max_features': 0.1,'n_estimators':100}\n",
    "RF_clf = RandomForestClassifier(max_depth=parameter2use['max_depth'],\\\n",
    "                            max_features=parameter2use['max_features'],\\\n",
    "                            n_estimators= parameter2use['n_estimators'],\\\n",
    "                            random_state=42)\n",
    "cv_score = cross_val_score(estimator=RF_clf, X=X_train_KNN, y=y_train, \\\n",
    "                           cv=5,scoring='f1_weighted')\n",
    "cv_pred = cross_val_predict(estimator=RF_clf, X=X_train_KNN, y=y_train, \\\n",
    "                            cv=5)\n",
    "cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     6\n",
       "1    21\n",
       "2    11\n",
       "3    38\n",
       "4    11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv_pred).astype(bool).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0625    , 0.15384615, 0.6       , 0.25581395, 0.1       ])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "F1_weighted_cv = f1_score(y_train,cv_pred,average = 'weighted')\n",
    "f1_score(y_train,cv_pred,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_clf.fit(X_train_KNN,y_train)\n",
    "test_pred = RF_clf.predict(X_test_KNN)\n",
    "F1_weighted_test = f1_score(y_test,test_pred,average = 'weighted')\n",
    "F1_weighted_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3278688524590164"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1_macro_test = f1_score(y_test,test_pred,average = 'macro')\n",
    "F1_macro_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
